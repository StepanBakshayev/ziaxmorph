==========================
HTTP-сервер склонения слов
==========================


Задание
=======

Написать модуль который поднимает http сервер (порт любой).
У которого на входе:

Хедеры:

    content-type: application/json
    key: [ключ авторизации] (для теста он должен быть "ziax" )

body:

    {"sentence": "любой текст который сюда напишем"}

sentence - любая текстовая фраза на русском

Ответ:

    {
    "status":"ok"
    "declined_word": ["любой", "любая"],
    "num_words": 5
    }

declined_word - все склонения первого слова во фразе
num_words - количество слов во фразе

Обработка ошибок:

1. Система должна принимать только кириллицу
2. в качестве первого слова может быть число
3. если sentence пустой то в ответе должно быть сообщение об ошибке


Реализация
==========

Морфология
----------

В прошлом, когда мне потребовалось склонение, я использовал `Морфер <http://morpher.ru/>`_.
Он платный, но 7 тр (за версию единоразово) были копейками в бюджете проекта (2 года разработки в одного меня). База пополняется - есть смысл покупать с какой-то регулярностью.
Хоть у него и нет версии для питона. Я запросил `С++ версию <https://morpher.ru/cpp/>`_ и выполнил обвязку на boost. Я совершил ошибку. Я струсил перед кастомными указателями в библиотеке. `pybind11 <https://pybind11.readthedocs.io/en/stable/>`_ справился бы.
Для тестового задания я буду использовать `pymorphy2 <https://pymorphy2.readthedocs.io/en/stable/index.html>`_, как указано в вакансии.


Лучший способ
-------------

Библиотека pymorphy2 обещает колосальную скорость работы. Локально у меня получилось для ``%time morph.parse('бурбаш')`` 202 µs в python 3.8 в версии fast (для pypy 3.7.9 e275e33444d9 1.14 ms в чистой версии).
Кажется, что можно оставить сделать выбор в пользу синхронного сервиса. `Это будет быстрее <http://calpaterson.com/async-python-is-not-faster.html>`_.
Однако, сеть остается непредсказуемой средой передачей данных с вероятностью задержки бесконечное количество времени. Один клиент со скоростью отправки байт в секунду может убить половину производительности из двух воркеров, третьи из трех, четверть из четырех и т.д.
В зависимости от среды развертывания и характера использования можно выбрать стрегию: перестраховка или простота реализации с метрикой за работой сети, что бы быть вкурсе, когда наши предположения о надежности работы сети разбились о реальность.
Перестраховка заключается в асинхронном фронтэнде, который бы буферизовал запрос до получения всех входных данных.
nginx служил мне такой перестраховкой. Здесь же это овердизайн. Возможно gunicorn предоставляет подобный сервис. Нужно вникать в его внутреннее устройство.

Лучший вариант я искать не буду - для "вымышленной" задачи вполне хватит "вымышленного" решения. Я отдам предпочтение простой и доступной для широких масс реализации gunicorn+WSGI applicaiton.
Если она не будет "справляться", тогда любой асинхронный фронтэнд (с настройками буферов, таймаутов) поможет сгладить непредсказуемость сети.


